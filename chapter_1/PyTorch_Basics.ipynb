{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.*\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/nlp-with-pytorch/blob/master/chapter_1/PyTorch_Basics.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/nlp-with-pytorch/blob/master/chapter_1/PyTorch_Basics.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 샘플과 타깃의 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = ['Time flies like an arrow.', \n",
    "          'Fruit flies like a banana.']\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
    "vocab = one_hot_vectorizer.get_feature_names()\n",
    "sns.heatmap(one_hot, annot=True,\n",
    "            cbar=False, xticklabels=vocab,\n",
    "            yticklabels=['Sentence 1', 'Sentence 2'])\n",
    "\n",
    "plt.savefig('1-04.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    " \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=vocab,\n",
    "            yticklabels= ['Sentence 1', 'Sentence 2'])\n",
    "\n",
    "plt.savefig('1-05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$IDF(w) = \\text{log} \\left(\\dfrac{N+1}{N_w+1}\\right)+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 문장의 'flies'와 'like'의 경우 TF = 1이므로 $\\text{TF-IDF}=1\\times\\text{log}\\left(\\dfrac{2+1}{2+1}\\right)+1=1$입니다.\n",
    "\n",
    "단어 'an', 'arrow', 'time'의 경우 $N_w=1$입니다. 따라서 $\\text{TF-IDF}=1\\times\\text{log}\\left(\\dfrac{2+1}{1+1}\\right)+1=1.4054651081081644$입니다.\n",
    "\n",
    "L2 정규화를 적용하면 'flies'와 'like'는 $\\dfrac{1}{\\sqrt{2\\times1^2+3\\times1.4054651081081644^2+}}=0.3552$가 됩니다.\n",
    "\n",
    "'an', 'arrow', 'time'는 $\\dfrac{1.4054651081081644}{\\sqrt{2\\times1^2+3\\times1.4054651081081644^2+}}=0.4992$가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f87a287c1f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 스칼라는 하나의 숫자입니다.\n",
    "* 벡터는 숫자의 배열입니다.\n",
    "* 행렬은 숫자의 2-D 배열입니다.\n",
    "* 텐서는 숫자의 N-D 배열입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크기를 지정하여 텐서를 만들 수 있습니다. 여기서는 행이 5개이고 열이 3개인 텐서를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"타입: {}\".format(x.type()))\n",
    "    print(\"크기: {}\".format(x.shape))\n",
    "    print(\"값: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[2.7003e-06, 1.3040e-11, 2.1352e+20],\n",
      "        [1.1039e-05, 1.6689e+22, 1.0324e-05]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[ 0.2310,  0.6931, -0.2669],\n",
      "        [ 2.1785,  0.1021, -0.2590]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.randn(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 크기의 랜덤한 텐서를 만드느 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0.9665, 0.7399, 0.4517],\n",
      "        [0.4757, 0.7842, 0.1525]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1이나 0으로 채워진 텐서를 만들 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.zeros(2, 3))\n",
    "x = torch.ones(2, 3)\n",
    "describe(x)\n",
    "x.fill_(5)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서를 초기화한 후 값을 바꿀 수 있습니다.\n",
    "\n",
    "노트: 밑줄 문자(`_`)로 끝나는 연산은 인-플레이스 연산입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.Size([3, 4])\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3,4).fill_(5)\n",
    "print(x.type())\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리스트의 리스트로 텐서를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 2])\n",
      "값: \n",
      "tensor([[1., 2.],\n",
      "        [2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2,],  \n",
    "                  [2, 4,]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이 배열로 텐서를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.DoubleTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0.5665, 0.9709, 0.4129],\n",
      "        [0.1934, 0.5026, 0.3364]], dtype=torch.float64)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "npy = np.random.rand(2, 3)\n",
    "describe(torch.from_numpy(npy))\n",
    "print(npy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 타입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FloatTensor has been the default tensor that we have been creating all along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3],  \n",
    "                       [4, 5, 6]])\n",
    "describe(x)\n",
    "\n",
    "x = x.long()\n",
    "describe(x)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6]], dtype=torch.int64)\n",
    "describe(x)\n",
    "\n",
    "x = x.float() \n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[-0.4175,  0.7618,  0.5356],\n",
      "        [ 1.5739, -0.4864, -0.6622]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[-0.8351,  1.5236,  1.0713],\n",
      "        [ 3.1477, -0.9729, -1.3244]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.add(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[-0.8351,  1.5236,  1.0713],\n",
      "        [ 3.1477, -0.9729, -1.3244]])\n"
     ]
    }
   ],
   "source": [
    "describe(x + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([6])\n",
      "값: \n",
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([3])\n",
      "값: \n",
      "tensor([3, 5, 7])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2])\n",
      "값: \n",
      "tensor([ 3, 12])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x, dim=0))\n",
    "describe(torch.sum(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([3, 2])\n",
      "값: \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(x, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([1, 2])\n",
      "값: \n",
      "tensor([[0, 1]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([])\n",
      "값: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)\n",
    "describe(x[:1, :2])\n",
    "describe(x[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 2])\n",
      "값: \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "describe(torch.index_select(x, dim=1, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 0])\n",
    "describe(torch.index_select(x, dim=0, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2])\n",
      "값: \n",
      "tensor([0, 4])\n"
     ]
    }
   ],
   "source": [
    "row_indices = torch.arange(2).long()\n",
    "col_indices = torch.LongTensor([0, 1])\n",
    "describe(x[row_indices, col_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱싱 연산에는 넘파이 `int64` 타입에 해당하는 LongTensor가 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([3, 3])\n",
      "값: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "torch.int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[1, 2, 3],  \n",
    "                      [4, 5, 6],\n",
    "                      [7, 8, 9]])\n",
    "describe(x)\n",
    "print(x.dtype)\n",
    "print(x.numpy().dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FloatTensor를 LongTensor로 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([3, 3])\n",
      "값: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3],  \n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "x = x.long()\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특별한 텐서 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자가 증가되는 벡터를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이따금 인덱싱을 위해 정수 기반의 배열이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 10).long()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산\n",
    "\n",
    "텐서로 선형 대수 계산을 하는 것은 최신 딥러닝 기술의 기초가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 `view` 메서드를 사용하면 원소의 순서를 유지하면서 텐서의 차원을 자유롭게 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n",
      "tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [16, 17],\n",
      "        [18, 19]])\n",
      "tensor([[ 0],\n",
      "        [ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [13],\n",
      "        [14],\n",
      "        [15],\n",
      "        [16],\n",
      "        [17],\n",
      "        [18],\n",
      "        [19]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 20)\n",
    "\n",
    "print(x.view(1, 20))\n",
    "print(x.view(2, 10))\n",
    "print(x.view(4, 5))\n",
    "print(x.view(5, 4))\n",
    "print(x.view(10, 2))\n",
    "print(x.view(20, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뷰를 사용하여 크기가 1인 차원을 추가할 수 있습니다. 이렇게 하면 다른 텐서와 연산할 때 브로드캐스팅을 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[0, 1, 2, 3]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "tensor([[ 0,  2,  4,  6],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 8, 10, 12, 14]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [10, 11, 12, 13]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "y = torch.arange(4).view(1, 4)\n",
    "z = torch.arange(3).view(3, 1)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(x + y)\n",
    "print(x + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze`와 `squeeze`는 크기가 1인 차원을 추가하고 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.unsqueeze(dim=1)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.squeeze()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표준 수학 연산을 모두 지원합니다(예를 들어 `add`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[0.5414, 0.6419, 0.2976, 0.7077],\n",
      "        [0.4189, 0.0655, 0.8839, 0.8083],\n",
      "        [0.7528, 0.8988, 0.6839, 0.7658]])\n",
      "--\n",
      "torch.add(x, x): \n",
      " tensor([[1.0828, 1.2838, 0.5952, 1.4153],\n",
      "        [0.8379, 0.1310, 1.7677, 1.6166],\n",
      "        [1.5056, 1.7977, 1.3677, 1.5317]])\n",
      "--\n",
      "x+x: \n",
      " tensor([[1.0828, 1.2838, 0.5952, 1.4153],\n",
      "        [0.8379, 0.1310, 1.7677, 1.6166],\n",
      "        [1.5056, 1.7977, 1.3677, 1.5317]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"--\")\n",
    "print(\"torch.add(x, x): \\n\", torch.add(x, x))\n",
    "print(\"--\")\n",
    "print(\"x+x: \\n\", x + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메서드 이름 끝에 `_` 문자가 있으면 인-플레이스(in-place) 연산을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([[ 0,  2,  4,  6],\n",
      "        [ 8, 10, 12, 14],\n",
      "        [16, 18, 20, 22]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "print(x)\n",
    "print(x.add_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차원을 줄이는 연산이 많이 있습니다. 예를 들면 `sum`입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "---\n",
      "행을 따라 덧셈 (dim=0): \n",
      " tensor([12, 15, 18, 21])\n",
      "---\n",
      "열을 따라 덧셈 (dim=1): \n",
      " tensor([ 6, 22, 38])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"---\")\n",
    "print(\"행을 따라 덧셈 (dim=0): \\n\", x.sum(dim=0))\n",
    "print(\"---\")\n",
    "print(\"열을 따라 덧셈 (dim=1): \\n\", x.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱싱, 슬라이싱, 연결, 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "---\n",
      "x[:2, :2]: \n",
      " tensor([[0, 1],\n",
      "        [3, 4]])\n",
      "---\n",
      "x[0][1]: \n",
      " tensor(1)\n",
      "---\n",
      "[0][1]에 8을 할당\n",
      "tensor([[0, 8, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"---\")\n",
    "print(\"x[:2, :2]: \\n\", x[:2, :2])\n",
    "print(\"---\")\n",
    "print(\"x[0][1]: \\n\", x[0][1])\n",
    "print(\"---\")\n",
    "print(\"[0][1]에 8을 할당\")\n",
    "x[0][1] = 8\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`index_select`을 사용해 텐서의 원소를 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "---\n",
      "tensor([[0, 1, 2],\n",
      "        [6, 7, 8]])\n",
      "---\n",
      "tensor([[0, 2],\n",
      "        [3, 5],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "print(x)\n",
    "\n",
    "print(\"---\")\n",
    "indices = torch.LongTensor([0, 2])\n",
    "print(torch.index_select(x, dim=0, index=indices))\n",
    "\n",
    "print(\"---\")\n",
    "indices = torch.LongTensor([0, 2])\n",
    "print(torch.index_select(x, dim=1, index=indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이 스타일의 인덱싱도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [6, 7, 8]])\n",
      "---\n",
      "tensor([[0, 1, 2],\n",
      "        [6, 7, 8]])\n",
      "---\n",
      "tensor([[0, 2],\n",
      "        [3, 5],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "indices = torch.LongTensor([0, 2])\n",
    "\n",
    "print(x[indices])\n",
    "print(\"---\")\n",
    "print(x[indices, :])\n",
    "print(\"---\")\n",
    "print(x[:, indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서를 연결할 수 있습니다. 먼저 행을 따라 열결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([4, 3])\n",
      "값: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 6])\n",
      "값: \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "타입: torch.LongTensor\n",
      "크기: torch.Size([2, 2, 3])\n",
      "값: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2,3)\n",
    "describe(x)\n",
    "describe(torch.cat([x, x], dim=0))\n",
    "describe(torch.cat([x, x], dim=1))\n",
    "describe(torch.stack([x, x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "열을 따라 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "---\n",
      "torch.Size([3, 9])\n",
      "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
      "        [6, 7, 8, 6, 7, 8, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "\n",
    "print(x)\n",
    "print(\"---\")\n",
    "new_x = torch.cat([x, x, x], dim=1)\n",
    "print(new_x.shape)\n",
    "print(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서를 쌓아 새로운 0번째 차원에 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "---\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "print(x)\n",
    "print(\"---\")\n",
    "new_x = torch.stack([x, x, x])\n",
    "print(new_x.shape)\n",
    "print(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형 대수 텐서 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전치는 다른 축의 차원을 서로 바꿉니다. 예를 들어 행과 열을 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "---\n",
      "x.tranpose(1, 0): \n",
      " tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 12).view(3,4)\n",
    "print(\"x: \\n\", x) \n",
    "print(\"---\")\n",
    "print(\"x.tranpose(1, 0): \\n\", x.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 텐서는 시퀀스의 배치로 표현됩니다. 시퀀스에 있는 각 아이템은 하나의 특성 벡터를 가집니다. 시퀀스 모델에서 시퀀스를 쉽게 인덱싱하기 위해 배치 차원과 시퀀스 차원을 바꾸는 일이 종종 있습니다.\n",
    "\n",
    "노트: 전치는 2개의 축을 바꿉니다. `permute`는 여러 축을 다룰 수 있습니다(다음 셀에서 설명합니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: \n",
      " torch.Size([3, 4, 5])\n",
      "x: \n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n",
      "-----\n",
      "x.transpose(1, 0).shape: \n",
      " torch.Size([4, 3, 5])\n",
      "x.transpose(1, 0): \n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [20, 21, 22, 23, 24],\n",
      "         [40, 41, 42, 43, 44]],\n",
      "\n",
      "        [[ 5,  6,  7,  8,  9],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [50, 51, 52, 53, 54]],\n",
      "\n",
      "        [[15, 16, 17, 18, 19],\n",
      "         [35, 36, 37, 38, 39],\n",
      "         [55, 56, 57, 58, 59]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "seq_size = 4\n",
    "feature_size = 5\n",
    "\n",
    "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
    "\n",
    "print(\"x.shape: \\n\", x.shape)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"x.transpose(1, 0).shape: \\n\", x.transpose(1, 0).shape)\n",
    "print(\"x.transpose(1, 0): \\n\", x.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`permute`는 전치의 일반화된 버전입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: \n",
      " torch.Size([3, 4, 5])\n",
      "x: \n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n",
      "-----\n",
      "x.permute(1, 0, 2).shape: \n",
      " torch.Size([4, 3, 5])\n",
      "x.permute(1, 0, 2): \n",
      " tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [20, 21, 22, 23, 24],\n",
      "         [40, 41, 42, 43, 44]],\n",
      "\n",
      "        [[ 5,  6,  7,  8,  9],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [50, 51, 52, 53, 54]],\n",
      "\n",
      "        [[15, 16, 17, 18, 19],\n",
      "         [35, 36, 37, 38, 39],\n",
      "         [55, 56, 57, 58, 59]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "seq_size = 4\n",
    "feature_size = 5\n",
    "\n",
    "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
    "\n",
    "print(\"x.shape: \\n\", x.shape)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"x.permute(1, 0, 2).shape: \\n\", x.permute(1, 0, 2).shape)\n",
    "print(\"x.permute(1, 0, 2): \\n\", x.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 곱셈은 `mm`입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8696,  1.8683, -2.6253],\n",
       "        [ 0.5689, -0.3702,  1.7509]], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 3])\n",
      "값: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([3, 2])\n",
      "값: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 2])\n",
      "값: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.arange(6).view(2, 3).float()\n",
    "describe(x1)\n",
    "\n",
    "x2 = torch.ones(3, 2)\n",
    "x2[:, 1] += 1\n",
    "describe(x2)\n",
    "\n",
    "describe(torch.mm(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "tensor([[ 6., 12.],\n",
      "        [22., 44.],\n",
      "        [38., 76.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 12).view(3,4).float()\n",
    "print(x)\n",
    "\n",
    "x2 = torch.ones(4, 2)\n",
    "x2[:, 1] += 1\n",
    "print(x2)\n",
    "\n",
    "print(x.mm(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 자세한 내용은 [파이토치 수학 연산 문서](https://pytorch.org/docs/stable/torch.html#math-operations)를 참고하세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레이디언트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 9.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2.0, 3.0]], requires_grad=True)\n",
    "z = 3 * x\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 간단한 코드에서 그레이디언트 계산을 엿볼 수 있습니다. 텐서 하나를 만들고 3을 곱합니다. 그다음 `sum()`을 사용해 스칼라 출력을 만듭니다. 손실 함수에는 스칼라 값이 필요하기 때문입니다. 그다음 손실에 `backward()`를 호출해 입력에 대한 변화율을 계산합니다. `sum()`으로 스칼라 값을 만들었기 때문에 `z`와 `x`에 있는 각 원소는 손실 스칼라 값에 대해 독립적입니다.\n",
    "\n",
    "출력에 대한 `x`의 변화율은 `x`에 곱한 상수 3입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[2., 3.]], requires_grad=True)\n",
      "---\n",
      "z = 3*x: \n",
      " tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
      "---\n",
      "loss = z.sum(): \n",
      " tensor(15., grad_fn=<SumBackward0>)\n",
      "---\n",
      "loss.backward()를 호출한 후, x.grad: \n",
      " tensor([[3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2.0, 3.0]], requires_grad=True)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"---\")\n",
    "z = 3 * x\n",
    "print(\"z = 3*x: \\n\", z)\n",
    "print(\"---\")\n",
    "\n",
    "loss = z.sum()\n",
    "print(\"loss = z.sum(): \\n\", loss)\n",
    "print(\"---\")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"loss.backward()를 호출한 후, x.grad: \\n\", x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제: 조건 그레이디언트 계산하기\n",
    "\n",
    "$$ \\text{x=1에서 f(x)의 그레이디언트 찾기} $$\n",
    "$$ {} $$\n",
    "$$ f(x)=\\left\\{\n",
    "\\begin{array}{ll}\n",
    "    sin(x) \\; x>0 \\text{ 일 때 }\\\\\n",
    "    cos(x) \\text{ 그 외 } \\\\\n",
    "\\end{array}\n",
    "\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if (x.data > 0).all():\n",
    "        return torch.sin(x)\n",
    "    else:\n",
    "        return torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = f(x)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 벡터에 적용할 수 있지만 출력은 스칼라 값이어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-89cb9bb7a7a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 에러가 발생합니다!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/nlp-with-pytorch/.env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/nlp-with-pytorch/.env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/nlp-with-pytorch/.env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
    "y = f(x)\n",
    "# 에러가 발생합니다!\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스칼라 출력을 만들어 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403, 0.8776])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
    "y = f(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 이슈가 있습니다. 이 함수는 예외적인 경우에 맞지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8415,  0.8415])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, -1], requires_grad=True)\n",
    "y = f(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4794, 0.8415])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([-0.5, -1], requires_grad=True)\n",
    "y = f(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 원소별로 불리언 연산과 코사인/사인 계산이 수행되지 않기 때문입니다. 이를 해결하기 위해 자주 사용되는 방법은 마스킹입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403, 0.8415])\n"
     ]
    }
   ],
   "source": [
    "def f2(x):\n",
    "    mask = torch.gt(x, 0).float()\n",
    "    return mask * torch.sin(x) + (1 - mask) * torch.cos(x)\n",
    "\n",
    "x = torch.tensor([1.0, -1], requires_grad=True)\n",
    "y = f2(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_grad(x):\n",
    "    if x.grad is None:\n",
    "        print(\"그레이디언트 정보 없음\")\n",
    "    else:\n",
    "        print(\"그레이디언트: \\n{}\".format(x.grad))\n",
    "        print(\"그레이디언트 함수: {}\".format(x.grad_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 2])\n",
      "값: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "그레이디언트 정보 없음\n",
      "--------\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([2, 2])\n",
      "값: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([])\n",
      "값: \n",
      "21.0\n",
      "그레이디언트 정보 없음\n",
      "--------\n",
      "그레이디언트: \n",
      "tensor([[2.2500, 2.2500],\n",
      "        [2.2500, 2.2500]], grad_fn=<CopyBackwards>)\n",
      "그레이디언트 함수: None\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "describe_grad(x)\n",
    "print(\"--------\")\n",
    "\n",
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "z = y.mean()\n",
    "describe(z)\n",
    "describe_grad(x)\n",
    "print(\"--------\")\n",
    "z.backward(create_graph=True, retain_graph=True)\n",
    "describe_grad(x)\n",
    "print(\"--------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f87783a8390>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치 연산은 GPU나 CPU에서 수행할 수 있습니다. 두 장치를 사용하기 위한 몇 가지 연산을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([3, 3])\n",
      "값: \n",
      "tensor([[0.8043, 0.3186, 0.2908],\n",
      "        [0.4196, 0.3728, 0.3769],\n",
      "        [0.0108, 0.9455, 0.7661]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입: torch.FloatTensor\n",
      "크기: torch.Size([3, 3])\n",
      "값: \n",
      "tensor([[0.2634, 0.1880, 0.5174],\n",
      "        [0.7849, 0.1412, 0.3112],\n",
      "        [0.7091, 0.1775, 0.4443]])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3).to(device)\n",
    "describe(x)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3864, 1.1518, 1.2869],\n",
       "        [0.8227, 0.3651, 0.9884],\n",
       "        [1.2365, 0.8100, 0.5353]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에러 발생!\n",
    "y = torch.rand(3, 3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3864, 1.1518, 1.2869],\n",
       "        [0.8227, 0.3651, 0.9884],\n",
       "        [1.2365, 0.8100, 0.5353]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.to(cpu_device)\n",
    "x = x.to(cpu_device)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): # GPU가 있을 경우에\n",
    "    a = torch.rand(3,3).to(device='cuda:0') #  CUDA 텐서\n",
    "    print(a)\n",
    "    \n",
    "    b = torch.rand(3,3).cuda()\n",
    "    print(b)\n",
    "\n",
    "    print(a + b)\n",
    "\n",
    "    a = a.cpu() # 에러 발생\n",
    "    print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 연습문제\n",
    "\n",
    "연습문제에 필요한 일부 연산은 이 노트북에 있지 않습니다. [파이토치 문서](https://pytorch.org/docs/)를 참고하세요!\n",
    "\n",
    "(정답은 맨 아래 있습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 1\n",
    "\n",
    "2D 텐서를 만들고 차원 0 위치에 크기가 1인 차원을 추가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 2 \n",
    "\n",
    "이전 텐서에 추가한 차원을 삭제하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제\u001f 3\n",
    "\n",
    "[3, 7) 범위를 갖는 5x3 크기의 랜덤한 텐서를 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 4\n",
    "\n",
    "정규 분포(평균=0, 표준편차=1)를 사용해 텐서를 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 5\n",
    "\n",
    "텐서 `torch.Tensor([1, 1, 1, 0, 1])`에서 0이 아닌 원소의 인덱스를 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 6\n",
    "\n",
    "(3,1) 크기가 인 랜덤한 텐서를 만들고 네 벌을 복사해 쌓으세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 7\n",
    "\n",
    "두 개의 2차원 행렬(`a=torch.rand(3,4,5)`, `b=torch.rand(3,5,4)`)의 배치 행렬 곱셈(batch matrix-matrix product)을 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 8\n",
    "\n",
    "3차원 행렬(`a=torch.rand(3,4,5)`)과 2차원 행렬(`b=torch.rand(5,4)`)의 배치 행렬 곱셈을 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답은 아래에.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답은 더 아래에.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 문제 1\n",
    "\n",
    "2D 텐서를 만들고 차원 0 위치에 크기가 1인 차원을 추가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2323, 0.7269, 0.1187],\n",
      "         [0.3951, 0.7199, 0.7595],\n",
      "         [0.5311, 0.6449, 0.7224]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "a = a.unsqueeze(0)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 문제 2 \n",
    "\n",
    "이전 텐서에 추가한 차원을 삭제하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = a.squeeze(0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 문제\u001f 3\n",
    "\n",
    "[3, 7) 범위를 갖는 5x3 크기의 랜덤한 텐서를 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7664, 4.4535, 6.5273],\n",
       "        [6.9496, 5.9264, 4.1257],\n",
       "        [3.2603, 3.0260, 5.0138],\n",
       "        [4.2326, 4.4967, 4.7188],\n",
       "        [6.8914, 6.8958, 4.8130]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + torch.rand(5, 3) * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 문제 4\n",
    "\n",
    "정규 분포(평균=0, 표준편차=1)를 사용해 텐서를 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1330, -2.9222, -1.3649],\n",
       "        [ 2.3648,  1.1561,  1.5042],\n",
       "        [-1.1678,  0.0582,  0.6402]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "a.normal_(mean=0, std=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 5\n",
    "\n",
    "텐서 `torch.Tensor([1, 1, 1, 0, 1])`에서 0이 아닌 원소의 인덱스를 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1, 1, 1, 0, 1])\n",
    "torch.nonzero(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 6\n",
    "\n",
    "(3,1) 크기가 인 랜덤한 텐서를 만들고 네 벌을 복사해 쌓으세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4245, 0.4245, 0.4245, 0.4245],\n",
       "        [0.9778, 0.9778, 0.9778, 0.9778],\n",
       "        [0.6800, 0.6800, 0.6800, 0.6800]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,1)\n",
    "a.expand(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제 7\n",
    "\n",
    "두 개의 2차원 행렬(`a=torch.rand(3,4,5)`, `b=torch.rand(3,5,4)`)의 배치 행렬 곱셈(batch matrix-matrix product)을 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8773, 1.5033, 2.0883, 0.7778],\n",
       "         [1.9376, 1.3167, 1.9028, 0.6165],\n",
       "         [1.9765, 1.5058, 1.7678, 1.0610],\n",
       "         [0.9175, 0.6772, 1.0179, 0.1880]],\n",
       "\n",
       "        [[0.7181, 1.5629, 0.5009, 1.2941],\n",
       "         [0.9486, 1.6072, 0.2210, 1.1375],\n",
       "         [0.6892, 1.6466, 0.5784, 0.7498],\n",
       "         [0.8756, 1.5032, 0.6305, 1.1023]],\n",
       "\n",
       "        [[0.8952, 0.6884, 0.8197, 1.2212],\n",
       "         [1.3024, 1.1315, 1.3545, 2.0788],\n",
       "         [1.0601, 1.3634, 1.3824, 2.0936],\n",
       "         [1.3985, 1.3368, 1.5873, 2.5252]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,4,5)\n",
    "b = torch.rand(3,5,4)\n",
    "torch.bmm(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 문제 8\n",
    "\n",
    "3차원 행렬(`a=torch.rand(3,4,5)`)과 2차원 행렬(`b=torch.rand(5,4)`)의 배치 행렬 곱셈을 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.2091, 1.0842, 1.6188, 1.9908],\n",
       "         [2.1884, 1.5238, 1.5916, 2.0331],\n",
       "         [2.4648, 1.3010, 1.7060, 2.2084],\n",
       "         [1.8721, 1.1840, 1.2810, 2.0882]],\n",
       "\n",
       "        [[1.5487, 0.8730, 1.1363, 1.3303],\n",
       "         [1.7827, 1.0264, 1.3035, 1.6133],\n",
       "         [2.5123, 1.5919, 1.9061, 2.2881],\n",
       "         [2.0718, 1.1121, 1.2656, 2.0963]],\n",
       "\n",
       "        [[1.9827, 1.3018, 1.6341, 1.8501],\n",
       "         [1.7645, 1.1482, 1.2656, 2.0402],\n",
       "         [2.5073, 1.4656, 1.7673, 2.4820],\n",
       "         [2.1340, 1.0845, 1.3597, 1.9435]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,4,5)\n",
    "b = torch.rand(5,4)\n",
    "torch.bmm(a, b.unsqueeze(0).expand(a.size(0), *b.size()))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
