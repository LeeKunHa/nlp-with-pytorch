{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chapter-6-Surname-Classification-with-RNNs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "120px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": "5",
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47166389f2bb45218b8762499dc65c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b243275156c540d0a997855d77834298",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_691cdd2f12f34e36bd7b0ff53d67a5ed",
              "IPY_MODEL_490ac0749bd84997a5140cea8c024c1a"
            ]
          }
        },
        "b243275156c540d0a997855d77834298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "691cdd2f12f34e36bd7b0ff53d67a5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9f6dd4ecefa44e18b4e0451cf9d0147",
            "_dom_classes": [],
            "description": "training routine: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1948a3ed38cb4130a4a741fe9494c5bc"
          }
        },
        "490ac0749bd84997a5140cea8c024c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb28a9e643674cfb88e2ee383d7c3b8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [06:35&lt;00:00,  3.94s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbf4b73996c44b5db90fb8043cb2c615"
          }
        },
        "a9f6dd4ecefa44e18b4e0451cf9d0147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1948a3ed38cb4130a4a741fe9494c5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb28a9e643674cfb88e2ee383d7c3b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbf4b73996c44b5db90fb8043cb2c615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8aa09c20c2e4f49b511db434cbd56d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b325344c531d4218ac76b712e8dc1ee4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7fc80d5700664cfcb85dd28f2f432ed5",
              "IPY_MODEL_f1a3d73fd7af442baaad8188f2043d92"
            ]
          }
        },
        "b325344c531d4218ac76b712e8dc1ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fc80d5700664cfcb85dd28f2f432ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4c7ad456abf4ceba79f16886109fa6c",
            "_dom_classes": [],
            "description": "split=train:  99%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 120,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 119,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae8a089374ad433697e9211bf7cea409"
          }
        },
        "f1a3d73fd7af442baaad8188f2043d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98d4fb60201549b0b2158e2e16b4c209",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 119/120 [06:35&lt;00:04,  4.96s/it, acc=45.2, epoch=99, loss=1.46]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0ef67c4f94c47f6aced3c8dccbd49e6"
          }
        },
        "f4c7ad456abf4ceba79f16886109fa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae8a089374ad433697e9211bf7cea409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98d4fb60201549b0b2158e2e16b4c209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0ef67c4f94c47f6aced3c8dccbd49e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "565a7ec3af7a4036aae0d754442608e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e560e5a2b26e4cea8df9dc315c1cd542",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc2071d21aeb410989471b91e93ab32f",
              "IPY_MODEL_10ce10a084724fac952f2fab7df9d7a2"
            ]
          }
        },
        "e560e5a2b26e4cea8df9dc315c1cd542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc2071d21aeb410989471b91e93ab32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_775e845424cc4402b0733d9c6de62677",
            "_dom_classes": [],
            "description": "split=val:  96%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d78e0f31329c4c92823e2c034ee6b76d"
          }
        },
        "10ce10a084724fac952f2fab7df9d7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83efe6c44aad461eb86527d7d49ca2d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24/25 [06:35&lt;00:04,  4.66s/it, acc=41.8, epoch=99, loss=1.82]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_455471c0334048d482a981e685515c4e"
          }
        },
        "775e845424cc4402b0733d9c6de62677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d78e0f31329c4c92823e2c034ee6b76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83efe6c44aad461eb86527d7d49ca2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "455471c0334048d482a981e685515c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMVPGGzLUYBx"
      },
      "source": [
        "*아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.*\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/nlp-with-pytorch/blob/master/chapter_6/classifying-surnames/Chapter-6-Surname-Classification-with-RNNs.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/nlp-with-pytorch/blob/master/chapter_6/classifying-surnames/Chapter-6-Surname-Classification-with-RNNs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_meQHzsoUYBy"
      },
      "source": [
        "# 성씨 분류\n",
        "\n",
        "이 예제에서 성씨를 분류해 보겠습니다.\n",
        "\n",
        "이 예제는 파이토치가 제공하는 `PackedSequence`의 처리 방식을 사용하도록 변경한 것입니다. `PackedSequence`가 편리하지만 열 인덱싱을 어떻게 처리하는지 이해하는 것은 유용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ddS8j7UYBz"
      },
      "source": [
        "from argparse import Namespace\n",
        "import os\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MekfmP7DUYBz"
      },
      "source": [
        "## `Vocabulary`, `Vectorizer`, `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJXCTrtNUYBz"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
        "\n",
        "        매개변수:\n",
        "            token (str): Vocabulary에 추가할 토큰\n",
        "        반환값:\n",
        "            index (int): 토큰에 상응하는 정수\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            tokens (list): 문자열 토큰 리스트\n",
        "        반환값:\n",
        "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
        "        \n",
        "        매개변수: \n",
        "            index (int): 찾을 인덱스\n",
        "        반환값:\n",
        "            token (str): 인텍스에 해당하는 토큰\n",
        "        에러:\n",
        "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNOOlxVRUYB0"
      },
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
        "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        노트:\n",
        "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
        "            `unk_index`가 0보다 커야 합니다.\n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEge6AuRUYB0"
      },
      "source": [
        "class SurnameVectorizer(object):\n",
        "    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n",
        "    def __init__(self, char_vocab, nationality_vocab):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            char_vocab (Vocabulary): 문자를 정수로 매핑합니다\n",
        "            nationality_vocab (Vocabulary): 국적을 정수로 매핑합니다\n",
        "        \"\"\"\n",
        "        self.char_vocab = char_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "\n",
        "    def vectorize(self, surname, vector_length=-1):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            title (str): 문자열\n",
        "            vector_length (int): 인덱스 벡터의 길이를 맞추기 위한 매개변수\n",
        "        \"\"\"\n",
        "        indices = [self.char_vocab.begin_seq_index]\n",
        "        indices.extend(self.char_vocab.lookup_token(token) \n",
        "                       for token in surname)\n",
        "        indices.append(self.char_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices)\n",
        "\n",
        "        out_vector = np.zeros(vector_length, dtype=np.int64)         \n",
        "        out_vector[:len(indices)] = indices\n",
        "        out_vector[len(indices):] = self.char_vocab.mask_index\n",
        "        \n",
        "        return out_vector, len(indices)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, surname_df):\n",
        "        \"\"\"데이터셋 데이터프레임으로 SurnameVectorizer 객체를 초기화합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 성씨 데이터셋\n",
        "        반환값:\n",
        "            SurnameVectorizer 객체\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary()\n",
        "        nationality_vocab = Vocabulary()\n",
        "\n",
        "        for index, row in surname_df.iterrows():\n",
        "            for char in row.surname:\n",
        "                char_vocab.add_token(char)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "\n",
        "        return cls(char_vocab, nationality_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
        "        nat_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "\n",
        "        return cls(char_vocab=char_vocab, nationality_vocab=nat_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'char_vocab': self.char_vocab.to_serializable(), \n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mZYzxxwUYB0"
      },
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, surname_df, vectorizer):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 데이터셋\n",
        "            vectorizer (SurnameVectorizer): 데이터셋에서 만든 Vectorizer 객체\n",
        "        \"\"\"\n",
        "        self.surname_df = surname_df \n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self._max_seq_length = max(map(len, self.surname_df.surname)) + 2\n",
        "\n",
        "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
        "                             'val': (self.val_df, self.validation_size), \n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "        # 클래스 가중치\n",
        "        class_counts = self.train_df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
        "        \"\"\"데이터셋을 로드하고 새로운 Vectorizer 객체를 만듭니다\n",
        "        \n",
        "        매개변수:\n",
        "            surname_csv (str): 데이터셋의 위치\n",
        "        반환값:\n",
        "            SurnameDataset의 객체\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        train_surname_df = surname_df[surname_df.split=='train']\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\n",
        "        \"\"\" 데이터셋과 새로운 Vectorizer 객체를 로드합니다.\n",
        "        캐시된 Vectorizer 객체를 재사용할 때 사용합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            surname_csv (str): 데이터셋의 위치\n",
        "            vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "        반환값:\n",
        "            SurnameDataset의 인스턴스\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(surname_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"파일에서 Vectorizer 객체를 로드하는 정적 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): 직렬화된 Vectorizer 객체의 위치\n",
        "        반환값:\n",
        "            SurnameVectorizer의 인스턴스\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"Vectorizer 객체를 json 형태로 디스크에 저장합니다\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"파이토치 데이터셋의 주요 진입 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            index (int): 데이터 포인트 인덱스\n",
        "        반환값:\n",
        "            다음 값을 담고 있는 딕셔너리:\n",
        "                특성 (x_data)\n",
        "                레이블 (y_target)\n",
        "                특성 길이 (x_length)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        surname_vector, vec_length = \\\n",
        "            self._vectorizer.vectorize(row.surname, self._max_seq_length)\n",
        "        \n",
        "        nationality_index = \\\n",
        "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "\n",
        "        return {'x_data': surname_vector, \n",
        "                'y_target': nationality_index, \n",
        "                'x_length': vec_length}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
        "        \n",
        "        매개변수:\n",
        "            batch_size (int)\n",
        "        반환값:\n",
        "            배치 개수\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    \n",
        "\n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\n",
        "    걱 텐서를 지정된 장치로 이동합니다.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-omdHXjrUYB1"
      },
      "source": [
        "## 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfw__0miUYB1"
      },
      "source": [
        "def column_gather(y_out, x_lengths):\n",
        "    ''' y_out에 있는 각 데이터 포인트에서 마지막 벡터 추출합니다\n",
        "\n",
        "    조금 더 구체적으로 말하면 배치 행 인덱스를 순회하면서\n",
        "    x_lengths에 있는 값에 해당하는 인덱스 위치의 벡터를 반환합니다.\n",
        "\n",
        "    매개변수:\n",
        "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
        "            shape: (batch, sequence, feature)\n",
        "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
        "            shape: (batch,)\n",
        "\n",
        "    반환값:\n",
        "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
        "            shape: (batch, feature)\n",
        "    '''\n",
        "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
        "\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(x_lengths):\n",
        "        out.append(y_out[batch_index, column_index])\n",
        "\n",
        "    return torch.stack(out)\n",
        "\n",
        "\n",
        "class ElmanRNN(nn.Module):\n",
        "    \"\"\" RNNCell을 사용하여 만든 엘만 RNN \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, batch_first=False):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            input_size (int): 입력 벡터 크기\n",
        "            hidden_size (int): 은닉 상태 벡터 크기\n",
        "            batch_first (bool): 0번째 차원이 배치인지 여부\n",
        "        \"\"\"\n",
        "        super(ElmanRNN, self).__init__()\n",
        "        \n",
        "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
        "        \n",
        "        self.batch_first = batch_first\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def _initial_hidden(self, batch_size):\n",
        "        return torch.zeros((batch_size, self.hidden_size))\n",
        "\n",
        "    def forward(self, x_in, initial_hidden=None):\n",
        "        \"\"\" ElmanRNN의 정방향 계산\n",
        "        \n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서 \n",
        "                If self.batch_first: x_in.shape = (batch_size, seq_size, feat_size)\n",
        "                Else: x_in.shape = (seq_size, batch_size, feat_size)\n",
        "            initial_hidden (torch.Tensor): RNN의 초기 은닉 상태\n",
        "        반환값:\n",
        "            hiddens (torch.Tensor): 각 타임 스텝에서 RNN 출력\n",
        "                If self.batch_first: \n",
        "                   hiddens.shape = (batch_size, seq_size, hidden_size)\n",
        "                Else: hiddens.shape = (seq_size, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        if self.batch_first:\n",
        "            batch_size, seq_size, feat_size = x_in.size()\n",
        "            x_in = x_in.permute(1, 0, 2)\n",
        "        else:\n",
        "            seq_size, batch_size, feat_size = x_in.size()\n",
        "    \n",
        "        hiddens = []\n",
        "\n",
        "        if initial_hidden is None:\n",
        "            initial_hidden = self._initial_hidden(batch_size)\n",
        "            initial_hidden = initial_hidden.to(x_in.device)\n",
        "\n",
        "        hidden_t = initial_hidden\n",
        "                    \n",
        "        for t in range(seq_size):\n",
        "            hidden_t = self.rnn_cell(x_in[t], hidden_t)\n",
        "            hiddens.append(hidden_t)\n",
        "            \n",
        "        hiddens = torch.stack(hiddens)\n",
        "\n",
        "        if self.batch_first:\n",
        "            hiddens = hiddens.permute(1, 0, 2)\n",
        "\n",
        "        return hiddens\n",
        "\n",
        "\n",
        "class SurnameClassifier(nn.Module):\n",
        "    \"\"\" RNN으로 특성을 추출하고 MLP로 분류하는 분류 모델 \"\"\"\n",
        "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
        "                 rnn_hidden_size, batch_first=True, padding_idx=0):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            embedding_size (int): 문자 임베딩의 크기\n",
        "            num_embeddings (int): 임베딩할 문자 개수\n",
        "            num_classes (int): 예측 벡터의 크기\n",
        "                노트: 국적 개수\n",
        "            rnn_hidden_size (int): RNN의 은닉 상태 크기\n",
        "            batch_first (bool): 입력 텐서의 0번째 차원이 배치인지 시퀀스인지 나타내는 플래그\n",
        "            padding_idx (int): 텐서 패딩을 위한 인덱스; \n",
        "                torch.nn.Embedding을 참고하세요\n",
        "        \"\"\"\n",
        "        super(SurnameClassifier, self).__init__()\n",
        "\n",
        "        self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
        "                                embedding_dim=embedding_size,\n",
        "                                padding_idx=padding_idx)\n",
        "        self.rnn = ElmanRNN(input_size=embedding_size,\n",
        "                             hidden_size=rnn_hidden_size,\n",
        "                             batch_first=batch_first)\n",
        "        self.fc1 = nn.Linear(in_features=rnn_hidden_size,\n",
        "                         out_features=rnn_hidden_size)\n",
        "        self.fc2 = nn.Linear(in_features=rnn_hidden_size,\n",
        "                          out_features=num_classes)\n",
        "\n",
        "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
        "        \"\"\" 분류기의 정방향 계산\n",
        "        \n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서 \n",
        "                x_in.shape는 (batch, input_dim)입니다\n",
        "            x_lengths (torch.Tensor): 배치에 있는 각 시퀀스의 길이\n",
        "                시퀀스의 마지막 벡터를 찾는데 사용합니다\n",
        "            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n",
        "                크로스-엔트로피 손실을 사용하려면 False로 지정합니다\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape는 (batch, output_dim)입니다.\n",
        "        \"\"\"\n",
        "        x_embedded = self.emb(x_in)\n",
        "        y_out = self.rnn(x_embedded)\n",
        "\n",
        "        if x_lengths is not None:\n",
        "            y_out = column_gather(y_out, x_lengths)\n",
        "        else:\n",
        "            y_out = y_out[:, -1, :]\n",
        "\n",
        "        y_out = F.relu(self.fc1(F.dropout(y_out, 0.5)))\n",
        "        y_out = self.fc2(F.dropout(y_out, 0.5))\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "\n",
        "        return y_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb1bEPyJUYB1"
      },
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYvoQ7z5UYB2"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cPSfZAZUYB2",
        "outputId": "4524ebbd-1fda-4cfd-d55b-1439e4b3f2c1"
      },
      "source": [
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch6/surname_classification\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    char_embedding_size=100,\n",
        "    rnn_hidden_size=64,\n",
        "    # 훈련 하이퍼파라미터\n",
        "    num_epochs=100,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=64,\n",
        "    seed=1337,\n",
        "    early_stopping_criteria=5,\n",
        "    # 실행 옵션\n",
        "    cuda=True,\n",
        "    catch_keyboard_interrupt=True,\n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        ")\n",
        "\n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
        "\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA 사용여부: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHz4XxdgUYB2",
        "outputId": "780274e7-7012-4816-ed5c-0bafb54bc270"
      },
      "source": [
        "# 만약 코랩에서 실행하는 경우 아래 코드를 실행하여 전처리된 데이터를 다운로드하세요.\n",
        "!mkdir data\n",
        "!wget https://git.io/JtSPf -O data/download.py\n",
        "!wget https://git.io/JtSPU -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-04 13:15:12--  https://git.io/JtSPf\n",
            "Resolving git.io (git.io)... 52.5.205.147, 52.200.171.63, 34.198.117.197, ...\n",
            "Connecting to git.io (git.io)|52.5.205.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_6/classifying-surnames/data/download.py [following]\n",
            "--2021-03-04 13:15:12--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_6/classifying-surnames/data/download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1572 (1.5K) [text/plain]\n",
            "Saving to: ‘data/download.py’\n",
            "\n",
            "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-04 13:15:12 (27.8 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
            "\n",
            "--2021-03-04 13:15:12--  https://git.io/JtSPU\n",
            "Resolving git.io (git.io)... 52.5.205.147, 52.200.171.63, 34.198.117.197, ...\n",
            "Connecting to git.io (git.io)|52.5.205.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_6/classifying-surnames/data/get-all-data.sh [following]\n",
            "--2021-03-04 13:15:13--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_6/classifying-surnames/data/get-all-data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 507 [text/plain]\n",
            "Saving to: ‘data/get-all-data.sh’\n",
            "\n",
            "data/get-all-data.s 100%[===================>]     507  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-04 13:15:13 (30.0 MB/s) - ‘data/get-all-data.sh’ saved [507/507]\n",
            "\n",
            "/content/data\n",
            "Trying to fetch /content/data/surnames/surnames.csv\n",
            "6it [00:00, 4661.20it/s]\n",
            "Trying to fetch /content/data/surnames/surnames_with_splits.csv\n",
            "8it [00:00, 4561.51it/s]\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          4
        ],
        "id": "PHzJCWo6UYB3"
      },
      "source": [
        "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
        "    # 체크포인트를 로드합니다.\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv, \n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer를 만듭니다.\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = SurnameClassifier(embedding_size=args.char_embedding_size, \n",
        "                               num_embeddings=len(vectorizer.char_vocab),\n",
        "                               num_classes=len(vectorizer.nationality_vocab),\n",
        "                               rnn_hidden_size=args.rnn_hidden_size,\n",
        "                               padding_idx=vectorizer.char_vocab.mask_index)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqXaE4BRUYB3"
      },
      "source": [
        "## 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "Bmk91Ds6UYB3"
      },
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"훈련 상태를 업데이트합니다.\n",
        "\n",
        "    콤포넌트:\n",
        "     - 조기 종료: 과대 적합 방지\n",
        "     - 모델 체크포인트: 더 나은 모델을 저장합니다\n",
        "\n",
        "    :param args: 메인 매개변수\n",
        "    :param model: 훈련할 모델\n",
        "    :param train_state: 훈련 상태를 담은 딕셔너리\n",
        "    :returns:\n",
        "        새로운 훈련 상태\n",
        "    \"\"\"\n",
        "\n",
        "    # 적어도 한 번 모델을 저장합니다\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장합니다\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "         \n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= loss_tm1:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "                train_state['early_stopping_best_val'] = loss_t\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "47166389f2bb45218b8762499dc65c7a",
            "b243275156c540d0a997855d77834298",
            "691cdd2f12f34e36bd7b0ff53d67a5ed",
            "490ac0749bd84997a5140cea8c024c1a",
            "a9f6dd4ecefa44e18b4e0451cf9d0147",
            "1948a3ed38cb4130a4a741fe9494c5bc",
            "cb28a9e643674cfb88e2ee383d7c3b8f",
            "fbf4b73996c44b5db90fb8043cb2c615",
            "e8aa09c20c2e4f49b511db434cbd56d1",
            "b325344c531d4218ac76b712e8dc1ee4",
            "7fc80d5700664cfcb85dd28f2f432ed5",
            "f1a3d73fd7af442baaad8188f2043d92",
            "f4c7ad456abf4ceba79f16886109fa6c",
            "ae8a089374ad433697e9211bf7cea409",
            "98d4fb60201549b0b2158e2e16b4c209",
            "c0ef67c4f94c47f6aced3c8dccbd49e6",
            "565a7ec3af7a4036aae0d754442608e8",
            "e560e5a2b26e4cea8df9dc315c1cd542",
            "fc2071d21aeb410989471b91e93ab32f",
            "10ce10a084724fac952f2fab7df9d7a2",
            "775e845424cc4402b0733d9c6de62677",
            "d78e0f31329c4c92823e2c034ee6b76d",
            "83efe6c44aad461eb86527d7d49ca2d9",
            "455471c0334048d482a981e685515c4e"
          ]
        },
        "id": "OGo3B6YfUYB3",
        "outputId": "36c531ab-9b01-40db-f5fa-71494c769dbd"
      },
      "source": [
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
        "                               total=args.num_epochs,\n",
        "                               position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                               total=dataset.get_num_batches(args.batch_size), \n",
        "                               position=1, \n",
        "                               leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                             total=dataset.get_num_batches(args.batch_size), \n",
        "                             position=1, \n",
        "                             leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계로 이루어집니다\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력을 계산합니다\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
        "                                x_lengths=batch_dict['x_length'])\n",
        "\n",
        "            # 단계 3. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    \n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            \n",
        "            # 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 상태 막대 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 단계 1. 출력을 계산합니다\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
        "                                x_lengths=batch_dict['x_length'])\n",
        "\n",
        "            # 단계 2. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 3. 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier, \n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(\"반복 중지\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47166389f2bb45218b8762499dc65c7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8aa09c20c2e4f49b511db434cbd56d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=120.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "565a7ec3af7a4036aae0d754442608e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=25.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpb2k2TTUYB4"
      },
      "source": [
        "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # 출력을 계산합니다\n",
        "    y_pred =  classifier(batch_dict['x_data'],\n",
        "                         x_lengths=batch_dict['x_length'])\n",
        "    \n",
        "    # 손실을 계산합니다\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # 정확도를 계산합니다\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AP8eUG4UYB4",
        "outputId": "7f6c87a6-e675-429c-a479-361285a218d8"
      },
      "source": [
        "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
        "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 손실: 1.8230122900009156;\n",
            "테스트 정확도: 42.87499999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVrA5wt_UYB4"
      },
      "source": [
        "### 추론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ451bg2UYB4"
      },
      "source": [
        "def predict_nationality(surname, classifier, vectorizer):\n",
        "    vectorized_surname, vec_length = vectorizer.vectorize(surname)\n",
        "    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(dim=0)\n",
        "    vec_length = torch.tensor([vec_length], dtype=torch.int64)\n",
        "    \n",
        "    result = classifier(vectorized_surname, vec_length, apply_softmax=True)\n",
        "    probability_values, indices = result.max(dim=1)\n",
        "    \n",
        "    index = indices.item()\n",
        "    prob_value = probability_values.item()\n",
        "\n",
        "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "\n",
        "    return {'nationality': predicted_nationality, 'probability': prob_value, 'surname': surname}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q72pyR-FUYB5",
        "outputId": "7cba7424-5eb6-4794-8657-1dcf3e4d272f"
      },
      "source": [
        "# surname = input(\"Enter a surname: \")\n",
        "classifier = classifier.to(\"cpu\")\n",
        "for surname in ['McMahan', 'Nakamoto', 'Wan', 'Cho']:\n",
        "    print(predict_nationality(surname, classifier, vectorizer))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nationality': 'Irish', 'probability': 0.5085956454277039, 'surname': 'McMahan'}\n",
            "{'nationality': 'Japanese', 'probability': 0.5564090609550476, 'surname': 'Nakamoto'}\n",
            "{'nationality': 'Chinese', 'probability': 0.41471144556999207, 'surname': 'Wan'}\n",
            "{'nationality': 'Chinese', 'probability': 0.3648815155029297, 'surname': 'Cho'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}